
---
üë§ Autor
```
Mart√≠n And√∫jar
CEIA ‚Äî 2025
```

Este repositorio re√∫ne la resoluci√≥n completa de los Desaf√≠os 1, 2, 3 y 4 de la materia, conformando un
recorrido progresivo por distintas etapas del aprendizaje profundo aplicado.

El trabajo comienza con el preprocesamiento y an√°lisis exploratorio de datos (Desaf√≠o 1), contin√∫a con la
construcci√≥n de modelos basales y primeros enfoques supervisados (Desaf√≠o 2) y avanza hacia la experimentaci√≥n
con arquitecturas m√°s complejas como redes neuronales profundas (Desaf√≠o 3).

Finalmente, el Desaf√≠o 4 desarrolla un modelo de traducci√≥n autom√°tica basado en la arquitectura seq2seq
encoder‚Äìdecoder utilizando TensorFlow/Keras. Este modelo incluye tokenizaci√≥n biling√ºe, generaci√≥n de secuencias
con `<sos>` y `<eos>`, entrenamiento sobre miles de pares de oraciones, experimentos variando la cantidad de
neuronas internas (`latent_dim`) y la implementaci√≥n de distintas estrategias de decodificaci√≥n
(greedy, sampling, top-k y beam search). Adem√°s, se incorpora una variante opcional con embeddings
pre-entrenados (GloVe).

En conjunto, estos trabajos cubren el pipeline completo de aprendizaje profundo: preparaci√≥n de datos, modelos
base, redes avanzadas y la aplicaci√≥n de t√©cnicas modernas de **Procesamiento de Lenguaje Natural (NLP)** para
resolver un problema real de traducci√≥n autom√°tica.


# Desaf√≠o 1 ‚Äî Preprocesamiento y an√°lisis exploratorio

En este desaf√≠o se trabaja con:

- Limpieza y normalizaci√≥n de datos.
- An√°lisis exploratorio detallado.
- Visualizaciones descriptivas.
- Preparaci√≥n del dataset para tareas de modelado posteriores.

El objetivo es establecer un pipeline de preprocesamiento claro y reproducible.

---

# Desaf√≠o 2 ‚Äî Modelos cl√°sicos / Baselines supervisados

Incluye:

- Divisi√≥n del dataset en subconjuntos de entrenamiento y validaci√≥n.
- Entrenamiento de modelos base (seg√∫n la consigna de la materia).
- Evaluaci√≥n con m√©tricas relevantes.
- Identificaci√≥n de overfitting / underfitting.
- Primeros ajustes de hiperpar√°metros.

Este desaf√≠o establece un punto de referencia para modelos m√°s complejos.

---

# Desaf√≠o 3 ‚Äî Modelos avanzados (CNN / RNN )

Este desaf√≠o incorpora arquitecturas m√°s expresivas:

- Redes neuronales profundas.
- Experimentaci√≥n con capas, activaciones y regularizaci√≥n.
- An√°lisis de curvas de entrenamiento.
- Comparaci√≥n entre configuraciones y discusi√≥n de resultados.

El objetivo es profundizar la comprensi√≥n de arquitecturas modernas y su comportamiento.

---

# Desaf√≠o 4 ‚Äî Traductor Seq2Seq (TensorFlow / Keras)

El cuarto desaf√≠o implementa un modelo **encoder‚Äìdecoder con LSTM** para traducir texto de **ingl√©s ‚Üí espa√±ol**, extendiendo el ejemplo provisto en la Clase 6.

### Componentes principales

- Preprocesamiento del dataset Anki / ManyThings.
- Tokenizaci√≥n independiente por idioma.
- Construcci√≥n de secuencias con `<sos>` y `<eos>`.
- Arquitectura seq2seq est√°ndar:
    - **Encoder:** Embedding + LSTM
    - **Decoder:** Embedding + LSTM + Dense(softmax)
- Entrenamiento con secuencias de longitud configurable.
- Evaluaci√≥n cualitativa mediante 5+ ejemplos reales.
- Implementaci√≥n de m√∫ltiples estrategias de decodificaci√≥n:
    - Greedy decoding
    - Sampling con temperatura
    - Top-k sampling
    - Beam search
- Experimentos sistem√°ticos variando el tama√±o del estado interno (`latent_dim`).
- Celda opcional para integrar **embeddings GloVe pre-entrenados**.

### Objetivos alcanzados

- Reproducir y **extender** el traductor original de la Clase 6.
- Analizar emp√≠ricamente c√≥mo influye la capacidad del modelo.
- Explorar estrategias de inferencia y sus efectos en la calidad de traducci√≥n.
- Sentar las bases para introducci√≥n de mecanismos de atenci√≥n.

---

# Requisitos

**Python:** 3.9+  
**Dependencias principales:**

- tensorflow / keras
- numpy
- pandas
- matplotlib
- seaborn
- scikit-learn
- tqdm

Los notebooks est√°n pensados para ejecutarse f√°cilmente en **Google Colab** sin configuraciones adicionales.

---

# ‚ñ∂C√≥mo ejecutar

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/usuario/repositorio.git
   cd repositorio
    ```
2. Abrir cualquier notebook en Jupyter o Colab.

3. Ejecutar las celdas en orden.

4. Para el Desaf√≠o 4, asegurarse de ejecutar primero la celda que descarga el dataset `spa-eng`.   
